{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bcb6883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Limud\\spcup\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\Limud\\spcup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a44bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mrmr_selection in c:\\users\\gilka\\appdata\\roaming\\python\\python39\\site-packages (0.2.6)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mrmr_selection) (2.11.3)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.1.0)\n",
      "Requirement already satisfied: category-encoders in c:\\users\\gilka\\appdata\\roaming\\python\\python39\\site-packages (from mrmr_selection) (2.6.0)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\gilka\\appdata\\roaming\\python\\python39\\site-packages (from mrmr_selection) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from mrmr_selection) (4.64.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->mrmr_selection) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->mrmr_selection) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0.3->mrmr_selection) (1.16.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders->mrmr_selection) (0.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders->mrmr_selection) (0.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->mrmr_selection) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category-encoders->mrmr_selection) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category-encoders->mrmr_selection) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->mrmr_selection) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->mrmr_selection) (0.4.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in c:\\users\\gilka\\appdata\\roaming\\python\\python39\\site-packages (3.3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\gilka\\appdata\\roaming\\python\\python39\\site-packages (from lightgbm) (1.21.6)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import List\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "!pip install mrmr_selection\n",
    "!pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc4c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_load_files(dir_path, file_name):\n",
    "    files = [np.load(os.path.join(root, file)).T\n",
    "             for root, dirs, files in os.walk(dir_path) \n",
    "             for file in files if(file.endswith(file_name))]\n",
    "    try:\n",
    "        files = np.stack(files)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return files\n",
    "\n",
    "def pd_load_test_files(dir_path, file_name, transpose = False):\n",
    "    if transpose:\n",
    "        \n",
    "        files = {root[10:]: pd.DataFrame(np.load(os.path.join(root, file)).T)\n",
    "             for root, dirs, files in os.walk(dir_path) \n",
    "             for file in files if(file.endswith(file_name)) if 'sub' in root}\n",
    "    else:\n",
    "        files = {root[10:]: pd.DataFrame(np.load(os.path.join(root, file)))\n",
    "             for root, dirs, files in os.walk(dir_path) \n",
    "             for file in files if(file.endswith(file_name)) if 'sub' in root}\n",
    "    return pd.concat(files, axis=1)\n",
    "\n",
    "def vector_to_matrix(vector):\n",
    "    res = []\n",
    "    for subject in vector:\n",
    "        n = int(np.sqrt(2 * len(subject))) + 1\n",
    "        mat = np.zeros((n, n))\n",
    "        idx = np.triu_indices(n, k=1)  # k=1 skips the main diagonal\n",
    "        mat[idx] = subject\n",
    "        res.append(mat + mat.T + np.eye(n))\n",
    "    return res\n",
    "\n",
    "def matrix_to_vector(data):\n",
    "    return np.stack([[val for i, row in enumerate(array) for j, val in enumerate(row) if i < j] for array in data])\n",
    "\n",
    "def transform_to_log(data):\n",
    "    transformed_data = []\n",
    "    mat_data = vector_to_matrix(data)\n",
    "    for mat in mat_data:\n",
    "        S, vl = scipy.linalg.eig(mat)\n",
    "        transformed_data.append( (vl @ np.diag(np.log(S)) @ vl.T).real )\n",
    "    return matrix_to_vector(transformed_data)\n",
    "\n",
    "def find_matrix_indices(k, n):\n",
    "    for i in range(n):\n",
    "        if i == np.floor((2*k + (i+1)*(i+2))/(2*n)):\n",
    "            break\n",
    "    j = int(np.floor((k + (i+1)*(i+2) / 2) % n))\n",
    "    return i, j\n",
    "\n",
    "def shuffle_three_arrays(arr1, arr2, arr3):\n",
    "    import random\n",
    "    temp = list(zip(arr1, arr2, arr3))\n",
    "    random.shuffle(temp)\n",
    "    return zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc44551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "icn_bp = np_load_files(\"data/train/bp\", 'icn_tc.npy')\n",
    "fnc_bp = np_load_files(\"data/train/bp\", 'fnc.npy').squeeze()\n",
    "icn_sz = np_load_files(\"data/train/sz\", 'icn_tc.npy')\n",
    "fnc_sz = np_load_files(\"data/train/sz\", 'fnc.npy').squeeze()\n",
    "icn_test = np_load_files(\"data/test\", 'icn_tc.npy')\n",
    "fnc_test = np_load_files(\"data/test\", 'fnc.npy').squeeze()\n",
    "fnc_test_df = pd_load_test_files(\"data/test\", 'fnc.npy')\n",
    "dfnc_train_bp = np_load_files(\"data/train/bp\", 'dFNC.npy')\n",
    "dfnc_train_sz = np_load_files(\"data/train/sz\", 'dFNC.npy')\n",
    "dfnc_test = fnc_test = np_load_files(\"data/test\", 'dFNC.npy')\n",
    "dfnc_test_df = pd_load_test_files(\"data/test\", 'dFNC.npy', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0afd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fnc in fnc_test:\n",
    "#     print(fnc.shape)\n",
    "fnc_test = fnc_test_df.to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46517a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc_bp = np.concatenate(dfnc_train_bp, axis=1)\n",
    "dfnc_sz = np.concatenate(dfnc_train_sz, axis=1)\n",
    "dfnc_test_cat = np.concatenate(dfnc_test,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ee2a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = fnc_sz.shape[0] + fnc_bp.shape[0]\n",
    "fnc_train = np.concatenate([fnc_sz, fnc_bp])\n",
    "dfnc_train = np.concatenate([dfnc_sz, dfnc_bp], axis=1).T\n",
    "m = dfnc_train.shape[0]\n",
    "y_train_dfnc = np.zeros(m)\n",
    "y_train_dfnc[dfnc_sz.shape[1]: ] = 1 \n",
    "\n",
    "y_train = np.zeros(n)\n",
    "y_train[fnc_sz.shape[0]: ] = 1 \n",
    "icn_train = icn_sz + icn_bp\n",
    "\n",
    "## shuffle examples\n",
    "res1, res2, res3 = shuffle_three_arrays(icn_train, fnc_train, y_train)\n",
    "icn_train, fnc_train, y_train = list(res1), np.stack(res2), np.stack(res3) \n",
    "\n",
    "## test\n",
    "test_subjects = np.stack(fnc_test_df.columns)[:, 0]\n",
    "test_subjects_dfnc = np.stack(dfnc_test_df.columns)[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe341eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(model_list: List[object], X_train, y_train, X_test, subjects_test,\n",
    "                save_test_predictions: bool = True, test_name: int = 0):\n",
    "    chosen_model = None\n",
    "    best_score = 0\n",
    "    final_scores = []\n",
    "    for model in model_list:\n",
    "        scores = []\n",
    "        k_fold = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "        for train_idx, val_idx in k_fold.split(X_train):\n",
    "            X_train_part, X_val, y_train_part, y_val = X_train[train_idx], X_train[val_idx], \\\n",
    "                                             y_train[train_idx], y_train[val_idx]\n",
    "            model.fit(X_train_part, y_train_part)\n",
    "            scores.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))\n",
    "        score = np.mean(scores)\n",
    "        print(f'model {model} average accuracy is = {score * 100}%')\n",
    "        if best_score < score:\n",
    "            chosen_model = model\n",
    "            best_score = score\n",
    "        if save_test_predictions:\n",
    "            model.fit(X_train, y_train)\n",
    "            test_prediction = model.predict_proba(X_test)[:, 1]\n",
    "            results = pd.DataFrame()\n",
    "            results['ID'] = subjects_test\n",
    "            results['Predicted'] = test_prediction\n",
    "            results = results.groupby(['ID']).mean()\n",
    "\n",
    "            # Save results:\n",
    "            file_name = 'results.csv'\n",
    "            results_file = f'results/{model.__class__.__name__}_{test_name}_{round(score, 2)}_{file_name}'\n",
    "            results.to_csv(results_file)\n",
    "        final_scores.append(test_prediction)\n",
    "    print(f'Best model is: {chosen_model}')\n",
    "    return chosen_model, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0944a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = {\n",
    "    'hidden_layer_sizes': [(100,), (10,), (100, 10,), ],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'alpha': [5e-2, 1e-3, 1e-4],}\n",
    "\n",
    "def create_models(sec_model_list: bool = True):\n",
    "    lgbm_model = LGBMClassifier(n_estimators=1000, random_state=0, max_depth=4, num_leaves=18)\n",
    "    optim_mlp_model = GridSearchCV(MLPClassifier(batch_size=500), mlp_params, n_jobs=-1)\n",
    "    mlp_model1 = MLPClassifier(activation='tanh', hidden_layer_sizes = (100, ), batch_size=500, alpha=0.05)\n",
    "    svm_model = GridSearchCV(SVC(probability=True, class_weight='balanced'), {'kernel': ['rbf', 'linear', 'poly'], 'C': [0.2, 0.5, 0.8, 1, 1.2, 1.5, 2]})\n",
    "    svm_model_rbf = SVC(probability=True, class_weight='balanced', kernel ='rbf', C=1.0)\n",
    "    rfc_model = RandomForestClassifier(n_estimators=100)\n",
    "    knn_model = GridSearchCV(KNeighborsClassifier(), {'n_neighbors': [3,5, 7,9, 11, 13]}, n_jobs=-1)\n",
    "    xgboost_model = GradientBoostingClassifier(n_estimators=1000, learning_rate=1.0, max_depth=4)\n",
    "    bagging_model = BaggingClassifier(SVC(probability=True, class_weight='balanced', C =1.0), n_estimators=3, random_state=10)\n",
    "    return  [svm_model_rbf, mlp_model1, xgboost_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test with original data\n",
    "models = create_models()\n",
    "best_model = test_models(models, dfnc_train, y_train_dfnc, dfnc_test_cat, test_subjects_dfnc, save_test_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588586c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test with mrmr data with selected features (19)\n",
    "return_scores = True\n",
    "selected_features = mrmr_classif(X=pd.DataFrame(fnc_train), y=y_train, K=19, return_scores=return_scores)\n",
    "if return_scores:\n",
    "    full_features = selected_features[1]\n",
    "    selected_features = selected_features[0]\n",
    "X_train_mrmr = fnc_train[:, selected_features]\n",
    "X_test_mrmr = fnc_test[:, selected_features]\n",
    "models = create_models()\n",
    "best_model, res = test_models(models, X_train_mrmr, y_train, X_test_mrmr, test_subjects, save_test_predictions=True, test_name=19_17_03_2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "949144bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fa5fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm, logm, expm, norm, inv\n",
    "\n",
    "def symmetric_matrix(A):\n",
    "    return (A + A.T) / 2\n",
    "\n",
    "\n",
    "def riemannian_mean(dFNC):\n",
    "    num_matrices = dFNC.shape[2]\n",
    "    if num_matrices == 1:\n",
    "        return dFNC\n",
    "    M = np.mean(dFNC, axis=2)\n",
    "    weights = (np.ones((num_matrices, 1)) / num_matrices)\n",
    "    for iteration in range(30):\n",
    "        A = sqrtm(M)\n",
    "        B = inv(A)\n",
    "        S = np.zeros_like(M)\n",
    "        for j in range(num_matrices):\n",
    "            current_matrix = dFNC[:, :, j]\n",
    "            if scipy.linalg.eig(current_matrix)[0].min() <= 0:\n",
    "                continue\n",
    "            BCB = symmetric_matrix(B @ current_matrix @ B)\n",
    "            S += weights[j] * logm(BCB).real\n",
    "        M = symmetric_matrix(A @ expm(S) @ A)\n",
    "        if norm(S, 'fro') < 1e-6:\n",
    "            break\n",
    "    return M.real\n",
    "\n",
    "\n",
    "def conjection(e_dict, labels, fnc_data):\n",
    "    rei_data = []\n",
    "    fnc_mat_data = np.stack(vector_to_matrix(fnc_data))\n",
    "    for label, fnc in zip(labels, fnc_mat_data):\n",
    "        E = e_dict[label]\n",
    "        fnc_hat = E @ fnc @ E.T\n",
    "        rei_data.append(fnc_hat)\n",
    "    fnc_hat = np.stack(rei_data)\n",
    "    fnc_hat = np.stack(matrix_to_vector(fnc_hat.real))\n",
    "    return fnc_hat\n",
    "\n",
    "def build_E(full_dict):\n",
    "    e_dict = {}\n",
    "    for key, data in full_dict.items():\n",
    "        print(f'Key={key}')\n",
    "        mat_data = np.stack(vector_to_matrix(data))\n",
    "        x_bar = riemannian_mean(mat_data.transpose(1,2,0)).squeeze()\n",
    "        e_dict[key] = scipy.linalg.fractional_matrix_power(x_bar, -0.5)\n",
    "    return e_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b663d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of each group: {234: 65, 230: 364, 204: 244, 100: 8, 134: 95, 210: 9, 208: 1}\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def create_fnc_diff(labels, fncs):\n",
    "    diff_len = OrderedDict()\n",
    "    for label, fnc in zip(labels, fncs):\n",
    "        if label in diff_len:\n",
    "            diff_len[label].append(fnc)\n",
    "        else:\n",
    "            diff_len[label] = [fnc]\n",
    "    return diff_len\n",
    "\n",
    "\n",
    "# kmeans = KMeans(n_clusters=6, random_state=100, init='k-means++').fit(np.concatenate([fnc_train_log,fnc_test_log]))\n",
    "full_data_dict = create_fnc_diff([icn.shape[1] for icn in icn_train + icn_test], np.concatenate([fnc_train, fnc_test]))\n",
    "group_sizes = {key: len(val) for key, val in full_data_dict.items()}\n",
    "print(f'The size of each group: {group_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ea9d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key=230\n",
      "Key=204\n",
      "Key=134\n",
      "Key=234\n",
      "Key=100\n",
      "Key=210\n",
      "Key=208\n"
     ]
    }
   ],
   "source": [
    "e_dict = build_E(full_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "453373e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_riemann = conjection(e_dict, [icn.shape[1] for icn in icn_train], fnc_train)\n",
    "X_test_riemann = conjection(e_dict, [icn.shape[1] for icn in icn_test], fnc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a892e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test with riemann full data\n",
    "models = create_models()\n",
    "best_model, scores = test_models(models, dfnc_train, y_train_dfnc, dfnc_test, test_subjects_dfnc, save_test_predictions=True, test_name='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59472c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc_test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc73fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [04:51<00:00, 15.35s/it]\n"
     ]
    }
   ],
   "source": [
    "return_scores = True\n",
    "selected_features_rei = mrmr_classif(X=pd.DataFrame(dfnc_train), y=y_train_dfnc, K=19, return_scores=return_scores)\n",
    "if return_scores:\n",
    "    full_features = selected_features_rei[1]\n",
    "    selected_features_rei = selected_features_rei[0]\n",
    "X_train_riemann_mrmr = dfnc_train[:, selected_features_rei]\n",
    "X_test_riemann_mrmr = dfnc_test_cat[:, selected_features_rei]\n",
    "\n",
    "models = create_models()\n",
    "best_model, res = test_models(models, X_train_riemann_mrmr, y_train_dfnc, X_test_riemann_mrmr, test_subjects_dfnc, save_test_predictions=True, test_name=f'mrmr{19}={21_03_2023}_right_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db558ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(full_features, reverse=True))\n",
    "plt.title('MRMR features relavence')\n",
    "plt.show()\n",
    "full_features = np.stack(full_features)\n",
    "len(full_features[full_features>5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "833d0158",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X_train_riemann_embed \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, perplexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(fnc_train)\n\u001b[1;32m----> 6\u001b[0m X_test_riemann_embed \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfnc_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1108\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \n\u001b[0;32m   1091\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:813\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquare_distances\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be True or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegacy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;66;03m# See issue #18018\u001b[39;00m\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_exaggeration \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate, \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "\n",
    "X_train_riemann_embed = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(fnc_train)\n",
    "X_test_riemann_embed = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(fnc_test)\n",
    "\n",
    "# X_train_riemann_embed = umap.UMAP().fit_transform(X_train_riemann_mrmr)\n",
    "# X_test_riemann_embed = umap.UMAP().fit_transform(X_test_riemann_mrmr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"y\"] = y_train\n",
    "df[\"x1\"] = X_train_riemann_embed[:,0]\n",
    "df[\"x2\"] = X_train_riemann_embed[:,1]\n",
    "\n",
    "sns.scatterplot(x=\"x1\", y=\"y\", data=df) \n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"y\"] = np.zeros(315)\n",
    "df[\"x1\"] = X_test_riemann_embed[:,0]\n",
    "df[\"x2\"] = X_test_riemann_embed[:,1]\n",
    "\n",
    "sns.scatterplot(x=\"x1\", y=\"x2\", hue=df.y.tolist(),palette=sns.color_palette(\"hls\",1), data=df) \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
